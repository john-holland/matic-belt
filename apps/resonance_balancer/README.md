# Local Area Resonance Balancer ğŸ”‡

Experimental audio utility that listens to the immediate environment, learns repeating resonance patterns (fan hum, fluorescent buzz, HVAC drones), and emits a phase-inverted signal to muffle or cancel that narrow band of sound.

> Think â€œnoise-cancelling headphones,â€ but projected into a room using commodity microphones and speakers.

---

## System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   mic array   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   inverted gain   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ambient    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Analyzer   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Resonance TX â”‚
â”‚ Soundfield â”‚               â”‚ (FFT + ML) â”‚                   â”‚ (Speaker Bus)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–²                          â”‚                                 â”‚
        â”‚      adaptive feedback   â–¼                                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Feature Highlights

- **Local Area Averaging** â€“ rolling capture buffer (default 4.2â€¯s) with overlap-add to emphasize persistent tones over transients.
- **Resonance Fingerprinting** â€“ bucketized FFT bins + simple online clustering to spot repeated peaks.
- **Phase-Aligned Cancellation** â€“ `AudioWorkletProcessor` emits the inverted waveform with latency compensation derived from `audioContext.baseLatency`.
- **Safety Envelope** â€“ smart limiter ensures emitted cancellation never exceeds 78â€¯dB SPL.
- **Tunable Zones** â€“ optional HRTF-based spatialization lets you target a â€œmuffling bubble.â€

---

## Implementation Sketch

```ts
// apps/resonance_balancer/src/index.ts (future)
const ctx = new AudioContext();
const mic = await navigator.mediaDevices.getUserMedia({ audio: true });
const source = ctx.createMediaStreamSource(mic);

const analyzer = new ResonanceTracker({ windowSize: 8192, overlap: 0.5 });
source.connect(analyzer.node);

const canceller = new ResonanceCanceller({ gain: -0.8, latencyComp: ctx.baseLatency });
analyzer.connect(canceller.input);
canceller.output.connect(ctx.destination);
```

---

## Running the Prototype

```bash
npm install
npm run dev  # Vite dev server (planned)
```

The current prototype ships with mock data + Web Audio scaffolding so you can start experimenting immediately.

---

## Next Steps

- Hook up multi-mic array calibration (support Dante / USB aggregate devices).
- Add UI for selecting which resonance buckets to suppress vs. leave audible.
- Explore ML models (e.g., tiny CNN) for differentiating â€œpleasantâ€ tones from harsh ones.

---

*Built for Bat Belt experimentation. Use responsibly and mind local audio ordinances.* 
